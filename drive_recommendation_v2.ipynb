{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasmeet16-jtg/projects/virtualenvs/calyx_ds3/lib/python3.5/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasmeet16-jtg/projects/virtualenvs/calyx_ds3/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/jasmeet16-jtg/projects/virtualenvs/calyx_ds3/lib/python3.5/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "31\n",
      "31\n",
      "40\n",
      "50\n",
      "50\n",
      "60\n",
      "60\n",
      "71\n",
      "71\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def make_full_filled_clusters(temp_df, drive_no, min_req, max_req):\n",
    "    count_sum = temp_df['count'].sum()\n",
    "\n",
    "    if count_sum < max_req:\n",
    "        if count_sum < 0.2 * min_req:\n",
    "            temp_df['drive_no'] = drive_no if drive_no%10 == 0 else drive_no-1\n",
    "            return temp_df, drive_no\n",
    "        temp_df['drive_no'] = drive_no\n",
    "        drive_no += 1\n",
    "        return temp_df, drive_no\n",
    "    \n",
    "    return_df = pd.DataFrame()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2).fit(temp_df[['lat','lng']])\n",
    "    temp_df['internal_clusters'] = list(kmeans.labels_)\n",
    "    for i in range(2):\n",
    "        df = temp_df[temp_df['internal_clusters']==i]\n",
    "        res, drive_no = make_full_filled_clusters(df, drive_no, min_req, max_req)\n",
    "        return_df = pd.concat([return_df, res])\n",
    "    return return_df, drive_no\n",
    "\n",
    "BASEPATH = '/home/jasmeet16-jtg/projects/calyx_ds/src/models/drive_recommendation'\n",
    "min_req, max_req = 200, 400\n",
    "cluster_on_distance_file_path = os.path.join(BASEPATH, 'pool_recommendation_data/demo_drive_recommendation_cluster_on_distance.csv')\n",
    "output_file_path = os.path.join(BASEPATH, 'pool_recommendation_data/test.csv')\n",
    "cluster_on_distance = pd.read_csv(cluster_on_distance_file_path)\n",
    "fullfilled_drives = pd.DataFrame()\n",
    "for i in range(cluster_on_distance['cluster_number'].nunique()):\n",
    "    temp_df = cluster_on_distance[cluster_on_distance['cluster_number']==i]\n",
    "    group_obj = temp_df.groupby(by=['lat', 'lng'])['count'].sum().reset_index().rename(columns={'count':'count_sum'})\n",
    "    drive_no = i*10 + 0\n",
    "    for index, row in group_obj.iterrows():\n",
    "        if row['count_sum'] > min_req and row['count_sum'] < max_req:\n",
    "            drive_df = temp_df[(temp_df['lat']==row['lat']) & (temp_df['lng']==row['lng'])]\n",
    "            drive_df['drive_no'] = drive_no\n",
    "            drive_no += 1\n",
    "            fullfilled_drives = pd.concat([fullfilled_drives, drive_df])\n",
    "            temp_df = temp_df[(temp_df['lat'] != row['lat']) | (temp_df['lng'] != row['lng'])]\n",
    "        print(drive_no)\n",
    "    df, drive_no = make_full_filled_clusters(temp_df, drive_no, min_req, max_req)\n",
    "    fullfilled_drives = pd.concat([fullfilled_drives, df])\n",
    "# display(fullfilled_drives)\n",
    "fullfilled_drives.to_csv(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 20, 30, 31, 40, 50, 60, 70, 80, 90, 100, 110]\n"
     ]
    }
   ],
   "source": [
    "input_file = os.path.join(BASEPATH, 'pool_recommendation_data/test.csv')\n",
    "output_file = os.path.join(BASEPATH, 'pool_recommendation_data/final_output_test.csv')\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "def getuniq(l):\n",
    "    a = []\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        s = l[i]\n",
    "        a.append(s)\n",
    "        while i < len(l) and l[i] == s:\n",
    "            i += 1\n",
    "    return a\n",
    "\n",
    "\n",
    "centroid_lat, centroid_lng = [], []\n",
    "print(getuniq(df['drive_no']))\n",
    "for i in getuniq(df['drive_no']):\n",
    "    df1 = df[df['drive_no']==i]\n",
    "    lt = [df1['lat'].min(), df1['lng'].min()]\n",
    "    rb = [df1['lat'].max(), df1['lng'].max()]\n",
    "    centroid_lat.extend([(lt[0] + rb[0])/2] * len(df1))\n",
    "    centroid_lng.extend([(lt[1] + rb[1])/2] * len(df1))\n",
    "df['centriod_lat'] = centroid_lat\n",
    "df['centriod_lng'] = centroid_lng\n",
    "\n",
    "company_lat, company_lng = 28.503129, 77.083702\n",
    "df['lat_diff'] = df[['centriod_lat']].apply(lambda x: np.power(abs(x-company_lat), 2))\n",
    "df['lng_diff'] = df[['centriod_lng']].apply(lambda x: np.power(abs(x-company_lng), 2))\n",
    "df['distance'] = np.sqrt(df['lat_diff']+df['lng_diff'])\n",
    "df = df.sort_values(by='distance', ascending=True)\n",
    "df.to_csv(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calyx_ds3",
   "language": "python",
   "name": "calyx_ds3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
