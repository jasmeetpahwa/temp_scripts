{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN SKILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "# BASE_PATH = os.path.dirname(__file__)\n",
    "\n",
    "class CleanSkills():\n",
    "\n",
    "    def __init__(self, input_skill_file,  clean_skill_file, output_skill_file):\n",
    "        if type(input_skill_file) is pandas.core.frame.DataFrame:\n",
    "            self.input_skills_list = input_skill_file\n",
    "        else:\n",
    "            self.input_skills_list = pd.read_csv(input_skill_file)['skill']\n",
    "\n",
    "        if type(clean_skill_file) is pandas.core.frame.DataFrame:\n",
    "            self.clean_skills_list = clean_skill_file\n",
    "        else:\n",
    "            self.clean_skills_list = pd.read_csv(clean_skill_file)['skill']\n",
    "        self.output_clean_skill_file = output_skill_file\n",
    "        self.res = {}        \n",
    "\n",
    "    def clean_skills(self, output_type='DataFrame'):\n",
    "        result_df = pd.DataFrame()\n",
    "        cols = ['skill', 'clean_skill']\n",
    "\n",
    "        # self.input_skills_list = ['oracle database: 11g', 'self confidant', 'uv visible spectroscopy', 'junior software developer', 'angular material design', 'signal processsing']\n",
    "        for skill in self.input_skills_list:\n",
    "            skill = skill.strip()\n",
    "            if skill.lower() in self.res.keys():\n",
    "                skills_stat_df = pd.DataFrame({'skill':[skill], 'clean_skill':[self.res[skill.lower()]]})\n",
    "                result_df = result_df.append(skills_stat_df)\n",
    "                continue\n",
    "            skill_list, clean_skill_list, total_score_list, ratio_list, partial_ratio_list,\\\n",
    "            sort_ratio_list, partial_sort_ratio_list, set_ratio_list, partial_set_ratio_list = [], [], [], [], [], [], [], [], []\n",
    "            for clean_skill in self.clean_skills_list:\n",
    "                ratio = fuzz.ratio(skill, clean_skill)\n",
    "                partial_ratio = fuzz.partial_ratio(skill, clean_skill)\n",
    "                sort_ratio = fuzz.token_sort_ratio(skill, clean_skill)\n",
    "                partial_sort_ratio = fuzz.partial_token_sort_ratio(skill, clean_skill)\n",
    "                set_ratio = fuzz.token_set_ratio(skill, clean_skill)\n",
    "                partial_set_ratio = fuzz.partial_token_set_ratio(skill, clean_skill)\n",
    "\n",
    "                total_score = (1 * ratio) + (0.8 * set_ratio) + (0.8 * sort_ratio) + (0.5 * partial_ratio) + \\\n",
    "                              (0.3 * partial_set_ratio) + (0.3 * partial_sort_ratio)\n",
    "                \n",
    "                skill_list.append(skill)\n",
    "                clean_skill_list.append(clean_skill)\n",
    "                total_score_list.append(total_score)\n",
    "                ratio_list.append(ratio)\n",
    "                partial_ratio_list.append(partial_ratio)\n",
    "                sort_ratio_list.append(sort_ratio)\n",
    "                partial_sort_ratio_list.append(partial_sort_ratio)\n",
    "                set_ratio_list.append(set_ratio)\n",
    "                partial_set_ratio_list.append(partial_set_ratio)\n",
    "            skills_stat_df = pd.DataFrame({'skill':skill_list, 'clean_skill':clean_skill_list,\\\n",
    "                            'total_score':total_score_list, 'ratio':ratio_list,\\\n",
    "                            'partial_ratio':partial_ratio_list, 'sort_ratio':sort_ratio_list,\\\n",
    "                            'partial_sort_ratio':partial_sort_ratio_list, 'set_ratio':set_ratio_list, 'partial_set_ratio':partial_set_ratio_list})\\\n",
    "                            .sort_values(by=['total_score', 'ratio', 'sort_ratio', 'set_ratio', 'partial_ratio'], ascending=False)[:1]\n",
    "            self.res[skills_stat_df['skill'][0].lower()] = skills_stat_df['clean_skill'][0]\n",
    "            result_df = result_df.append(skills_stat_df[cols])\n",
    "\n",
    "        if output_type != 'DataFrame':\n",
    "            result_df.to_csv(self.output_clean_skill_file)\n",
    "        else:\n",
    "            return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATISE SKILLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import csv\n",
    "import sys\n",
    "import string\n",
    "\n",
    "class LemmatiseSkills():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        # nltk.download('wordnet')\n",
    "\n",
    "    def lemmatise_file(self, in_file, out_file):\n",
    "        with open(in_file, 'r') as input_file, open(out_file, 'w') as output_file:\n",
    "            line = input_file.readline()\n",
    "            while line:\n",
    "                flag = 0\n",
    "                for char in line:\n",
    "                    if ord(char) > 127:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag:\n",
    "                    line = input_file.readline()\n",
    "                    continue\n",
    "                line = line.translate(str.maketrans('-/', '  ', '&()'))\n",
    "                new_line = ''\n",
    "                for word in line.split(' '):\n",
    "                    word = word.strip().lower()\n",
    "                    lemma = self.wordnet_lemmatizer.lemmatize(word)\n",
    "                    new_line += word+' ' if len(word) <= 4 else lemma+' '\n",
    "                line = input_file.readline()\n",
    "                output_file.write('\"{new_line}\"\\n'.format(new_line=new_line.strip()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DRIVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LemmatiseSkills()\n",
    "ls.lemmatise_file('/home/jasmeet16-jtg/projects/temp_scripts/skill_standardization/all_skills.txt', \\\n",
    "                  '/home/jasmeet16-jtg/projects/temp_scripts/skill_standardization/all_skills_lemmatised.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calyx_ds3",
   "language": "python",
   "name": "calyx_ds3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
